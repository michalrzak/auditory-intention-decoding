@startuml
note as n
  <b>Note</b>: To save space, constructor parameter types,
  which match the types of the class parameters,
  are not specified
end note

class Audio {
        +NDArray[float] array
        +int sampling_frequency
    }

package view {
    abstract class AView<<Observer>> {
        #Callable[[Audio], None] sound_player
        #Dict[EExperimentState, Optional[str]] experiment_texts

        +AView(sound_player, experiment_texts)

        #void {abstract} update_new_stimulus(stimulus: CreatedStimulus)
        #void {abstract} updated_new_primer(primer: str)
        #void {abstract} update_experiment_state_changed(data: EExperimentState)
        +void update(data: Any, identifier: EModelUpdateIdentifier
        +bool {abstract} get_confirmation()
        +void {abstract} wait(secs: int)
    }

    class PsychopyView {
    }

    class CLIView {
    }
}

package model {
    abstract class AObserver {
        +void update(data: Any, identifier: EModelUpdateIdentifier)
    }

    class Model <<Observable>>{
        -List[str] primer_history

        -Model(raw_stimuli: List[Stimulus], auditory_stimulus_factories: List[AAudioTaggerFactory])
        -void notify(data: Any, identifier: EModelUpdateIdentifier)
        +void register(view: AObserver)
        +void new_stimulus(stimulus: CreatedStimulus)
        +void new_primer(stimulus: CreatedStimulus)
        +void change_experiment_state(new_state: EExperimentState)
    }

    class Logger<<Observer>> {
        -Path exports_directory
        +Logger(target_folder: PathLike)
    }
    Logger -u-|> AObserver

    package constants {
    enum EExperimentState {
        INACTIVE
        INTRODUCTION
        RESTING_STATE_EYES_OPEN
        RESTING_STATE_EYES_CLOSED
        EXPERIMENT_INTRODUCTION
        EXPERIMENT
    }

    enum EModelUpdateIdentifier {
        NEW_STIMULUS
        NEW_PRIMER
        EXPERIMENT_STATE_CHANGED
    }
    }

    class Stimulus {
        +str prompt
        +str primer
        +List[str] options
        +List[Tuple[float, float]] time_stamps
        +int target
    }
    Stimulus "1" *-- "1" Audio: audio

    class CreatedStimulus {
        -Stimulus stimulus
        +Optional[str] used_tagger_label

        +CreatedStimulus(stimulus: Stimulus, modified_audio: Audio)
        +str prompt()
        +str primer()
        +List[str] options()
        +List[Tuple[float, float]] time_stamps()
        +int target()
    }
    CreatedStimulus "1" *-- "1" Audio: modified_audio


    CreatedStimulus "*" *-l- "1" Stimulus
}

Model "1" *-r- "*" CreatedStimulus: "stimulus_history"
Model "*" o--- "1" EExperimentState: "experiment_state"
Model "1" o-l-- "*" AObserver
Model ..> EModelUpdateIdentifier: "uses"

AObserver .l.> constants: "uses"

AView --|> AObserver


package auditory_tagging {
    abstract class AAudioTagger {
      #NDArray[float] {abstract} modify_chunk(audio_array_chunk: NDArray[float], fs: int))
      +Audio create(audio, stimuli)
    }


    package assr_tagger {
        class AMTagger {
          -int frequency
          -Callable[[int, int, int], NDArray[float] tag_generator
          -[float, float] signal_interval

          +ASSRTagger(frequency, tag_generator, signal_interval)
        }

        class FMTagger {
          -int frequency
          -float modulation_factor

          +FMTagger(frequency, modulation_factor)
          -(NDArray[Real], NDArray[Real]) {static} extract_amplitudes_phases(numbers: NDArray[Complex])
          -NDArray[Complex] {static} get_complex_number(amplitudes: NDArray[Real], phases: NDArray[Real])
          -NDArray[Real] phases_to_instantaneous_frequencies(phases: NDArray[Real], fs: int)
          -NDArray[Real] instantaneous_frequencies_to_phases(instantaneous_frequencies: NDArray[Real], first_phase: NDArray[Real], fs: int)
          -NDArray[float32] modulate(signal: NDArray[float32])

        }

        class FlippedFMTagger {
          -int frequency

          +FlippedFMTagger(frequency)
        }
    }

    class NoiseTaggingTagger {
      -Optional[int] seed
      -int specified_fs
      -int bit_width
      -int length_bit
      +Optional[Code] code

      +NoiseTaggingTagger(fs:int, bits_per_second: int, length_bit, seed)
      -void __generate_code()
      -void __get_code(length: int)
    }

    class RawTagger {
    }

    package shift_taggers {
        class ShiftSumTagger {
          -int shift_by

          +ShiftSumTagger(shift_by)
        }

        class SpectrumShiftTagger {
          -int shift_by

          +SpectrumShiftTagger(shift_by)
        }

        class BinauralTagger {
            -int shift_by
            +BinauralTagger(shift_by)
        }
    }
}


package eeg {
   enum ETrigger{
     +ETrigger {static} get_trigger(data: Any, identifier: EModelUpdateIdentifier
   }
   note bottom of ETrigger: Contains tha mappings to\nthe actual trigger numbers\nsent

    abstract class ATriggerSender {
        -Queue trigger_queue
        -float thread_timout_secs
        -thread Thread
        -bool exit_flag
        -List[Trigger]: trigger_enqueue_threads

        +ATriggerSender(thread_timout_secs: float)
        -void trigger_worker()
        -void queue_trigger(trigger: ETrigger, offset_secs: float)
        #void {abstract} send_trigger(trigger: ETrigger)
        +ATriggerSender start()
        +void __del__()
    }
    note bottom
        This class uses a context management]
        (i.e. the with syntax) to start/stop threads.
        Call the start method to enter into a context
        which gets automatically cleaned up
        (the thread is killed).
    end note

   class BittiumTriggerSender {
     -IParallelPort parallel_port
     -int trigger_duration_s
     +BittiumTriggerSender(thread_timout_secs, parallel_port, trigger_duration_s)
     #void send_trigger(trigger: ETrigger)
   }

   class FileTriggerSender {
     -PathLike target_file
     +FileTriggerSender(thread_timout_secs, target_file)
   }
}

view -[hidden]- eeg

ATriggerSender -u-|> AObserver
BittiumTriggerSender -r-|> ATriggerSender
FileTriggerSender -d-|> ATriggerSender
ATriggerSender ..> ETrigger: "uses"

AAudioTagger <|-u- BinauralTagger
AAudioTagger <|-u- SpectrumShiftTagger
AAudioTagger <|-u- ShiftSumTagger
AAudioTagger <|-u- RawTagger
AAudioTagger <|-u- NoiseTaggingTagger
AAudioTagger <|-u- AMTagger
AAudioTagger <|-u- FMTagger
AAudioTagger <|-u- FlippedFMTagger


AView <|-- PsychopyView
AView <|-- CLIView



class Experiment {
    -Model model
    -AView view
    -int stimulus_repeat
    -float resting_state_secs
    -float primer_secs
    -float break_secs

    +Experiment(model, view, stimulus_repeat, resting_state_secs, primer_secs, break_secs)
    +void create_stimuli()
    +void run()
}
Experiment "1" *-- "1" Model
Experiment "1" *-- "1" AView

Model "1" *-u- "*" AAudioTagger
Model "1" *-- "*" Stimulus: raw_stimuli
Model "1" *-- "*" CreatedStimulus: created_stimuli
note on link: Created by calling  `create_stimuli()`

Experiment -[hidden] auditory_tagging
@enduml
